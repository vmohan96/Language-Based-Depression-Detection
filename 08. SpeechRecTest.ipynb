{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech-to-Text Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to Tommy Falgout; has a repo outlining how to implement speech recognition using microphone input:\n",
    "https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a preliminary test of the Speech Recognition library, as well as Google Cloud API's speech recognition functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = load_model('../data/model_l.hd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sr = load_model('../data/model_s.hd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WordVectorTransformer(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self, model=\"en_trf_distilbertbaseuncased_lg\"):    #put bert embeddings here\n",
    "        self.model = model\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        nlp = spacy.load(self.model)\n",
    "        return np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertvect = WordVectorTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we bring in the combine_predict function we built when we built the final composite predictive model; we will feed the speech to text recognized text into this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predict(sentence):\n",
    "    sentence = [[sentence]]\n",
    "\n",
    "    preds = np.array([])\n",
    "    s_input_model_l = np.array([bertvect.transform(i) for i in sentence]).reshape(-1,768,1)\n",
    "    s_input_model_s = pd.DataFrame([analyzer.polarity_scores(i) for i in sentence])\n",
    "    \n",
    "    preds_l = model_lr.predict(s_input_model_l)\n",
    "    preds_s = model_sr.predict(s_input_model_s)\n",
    "\n",
    "    preds = 0.7*preds_l+0.3*preds_s\n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU SAID: testing\n",
      "Model Prediction for Depression Probability: 0.3224950432777405\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    speech_output = r.recognize_google(audio)\n",
    "    print(f'YOU SAID: {speech_output}')\n",
    "    print(f'Model Prediction for Depression Probability: {combine_predict(speech_output)[0][0]}')\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
