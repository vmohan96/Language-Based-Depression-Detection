{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Vector Creation for Binary Depression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebook, the entire corpus consisting of depressive text and neutral text, 30,000 reddit posts each, are converted to bERT vectors via spaCy's transformer module and the distilbert language model, which offers faster processing with minimal losses in semantic accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import spacy\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU, Input, Flatten, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Input, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('../data/corpus.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why is it that the person who beats themself u...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dealing with sadness hi i’m will and i’ve been...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.8376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my life has never been better, and i feel as t...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.9637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it‘s my cake day!!!! :o i love reddit and will...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have weed dealer i colorado about 15 min...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>eye discomfort and heaviness when particularly...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>cbd gummies for anxiety hi, i recently bought ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>dae have to open their eyes multiple times whi...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.6848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>pandemic ruined my life, my work and dreams co...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>my first day of school was today... i skipped ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.6808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text           subreddit  \\\n",
       "0      why is it that the person who beats themself u...  CasualConversation   \n",
       "1      dealing with sadness hi i’m will and i’ve been...  CasualConversation   \n",
       "2      my life has never been better, and i feel as t...  CasualConversation   \n",
       "3      it‘s my cake day!!!! :o i love reddit and will...  CasualConversation   \n",
       "4      can i have weed dealer i colorado about 15 min...  CasualConversation   \n",
       "...                                                  ...                 ...   \n",
       "79995  eye discomfort and heaviness when particularly...             Anxiety   \n",
       "79996  cbd gummies for anxiety hi, i recently bought ...             Anxiety   \n",
       "79997  dae have to open their eyes multiple times whi...             Anxiety   \n",
       "79998  pandemic ruined my life, my work and dreams co...             Anxiety   \n",
       "79999  my first day of school was today... i skipped ...             Anxiety   \n",
       "\n",
       "       class    neg    neu    pos    comp  \n",
       "0          0  0.087  0.830  0.083 -0.0258  \n",
       "1          0  0.164  0.726  0.110 -0.8376  \n",
       "2          0  0.033  0.863  0.104  0.9637  \n",
       "3          0  0.032  0.617  0.351  0.9429  \n",
       "4          0  0.000  1.000  0.000  0.0000  \n",
       "...      ...    ...    ...    ...     ...  \n",
       "79995      2  0.177  0.773  0.050 -0.7116  \n",
       "79996      2  0.179  0.722  0.100 -0.3182  \n",
       "79997      2  0.093  0.840  0.067 -0.6848  \n",
       "79998      2  0.047  0.793  0.159  0.9421  \n",
       "79999      2  0.144  0.758  0.097 -0.6808  \n",
       "\n",
       "[80000 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full file includes posts from r/Anxiety, which we will not use for this analysis, so we exclude them to get depression and neutral text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = corpus[corpus['subreddit']!='Anxiety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why is it that the person who beats themself u...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dealing with sadness hi i’m will and i’ve been...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.8376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my life has never been better, and i feel as t...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.9637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it‘s my cake day!!!! :o i love reddit and will...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i have weed dealer i colorado about 15 min...</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text           subreddit  \\\n",
       "0  why is it that the person who beats themself u...  CasualConversation   \n",
       "1  dealing with sadness hi i’m will and i’ve been...  CasualConversation   \n",
       "2  my life has never been better, and i feel as t...  CasualConversation   \n",
       "3  it‘s my cake day!!!! :o i love reddit and will...  CasualConversation   \n",
       "4  can i have weed dealer i colorado about 15 min...  CasualConversation   \n",
       "\n",
       "   class    neg    neu    pos    comp  \n",
       "0      0  0.087  0.830  0.083 -0.0258  \n",
       "1      0  0.164  0.726  0.110 -0.8376  \n",
       "2      0  0.033  0.863  0.104  0.9637  \n",
       "3      0  0.032  0.617  0.351  0.9429  \n",
       "4      0  0.000  1.000  0.000  0.0000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Bert Vectors for the Whole Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = binary_df['full_text']\n",
    "y = binary_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WordVectorTransformer(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self, model=\"en_trf_distilbertbaseuncased_lg\"):    #put bert embeddings here\n",
    "        self.model = model\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        nlp = spacy.load(self.model)\n",
    "        return np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertvect = WordVectorTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bvect = bertvect.fit_transform(X_train)\n",
    "X_test_bvect = bertvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35125    1\n",
       "59835    1\n",
       "24115    0\n",
       "43143    1\n",
       "52381    1\n",
       "        ..\n",
       "49340    1\n",
       "54185    1\n",
       "37984    1\n",
       "8520     0\n",
       "6759     0\n",
       "Name: subreddit, Length: 48000, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = y_train.map({'depression':1,'CasualConversation':0,'happy':0})\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4067     0\n",
       "13389    0\n",
       "20021    0\n",
       "26140    0\n",
       "57845    1\n",
       "        ..\n",
       "58989    1\n",
       "32142    1\n",
       "40661    1\n",
       "50425    1\n",
       "3614     0\n",
       "Name: subreddit, Length: 12000, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat = y_test.map({'depression':1,'CasualConversation':0,'happy':0})\n",
    "y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vect = tf.keras.utils.to_categorical(y_train_cat)\n",
    "y_test_vect = tf.keras.utils.to_categorical(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bvect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bvect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy array as npy file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Vectors and Corresponding Classes as Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('X_train_bvect', X_train_bvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('X_test_bvect', X_test_bvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('y_train_vect', y_train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('y_test_vect', y_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "peek = load('X_train_bvect.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.640353 ,  25.654243 ,  50.3219   , ..., -67.152176 ,\n",
       "          7.7993217, -20.4163   ],\n",
       "       [ 45.34771  ,  64.30396  ,  47.350266 , ..., -11.698645 ,\n",
       "         26.163946 ,  -1.3377178]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.640353 ,  25.654243 ,  50.3219   , ..., -67.152176 ,\n",
       "          7.7993217, -20.4163   ],\n",
       "       [ 45.34771  ,  64.30396  ,  47.350266 , ..., -11.698645 ,\n",
       "         26.163946 ,  -1.3377178]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bvect[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshape = X_train_bvect.reshape(-1,768,1)\n",
    "X_test_reshape = X_test_bvect.reshape(-1,768,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 768, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 768, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Vectors Out on a Neural Net Classifier, One Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l = Sequential()\n",
    "\n",
    "model_l.add(Conv1D(32, 7, activation = 'relu'))\n",
    "model_l.add(MaxPooling1D())\n",
    "model_l.add(Bidirectional(LSTM(24)))\n",
    "model_l.add(Dense(64,activation='relu',kernel_regularizer=l2(0.001)))\n",
    "model_l.add(Dropout(0.5))\n",
    "model_l.add(Dense(64,activation='relu',kernel_regularizer=l2(0.001)))\n",
    "model_l.add(Dropout(0.5))\n",
    "model_l.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l.compile(optimizer='nadam', metrics=['accuracy'], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_l = model_l.fit(X_train_reshape, y_train_cat.to_numpy(), validation_data=(X_test_reshape,y_test_cat.to_numpy()), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33556902],\n",
       "       [0.12134761],\n",
       "       [0.0249674 ],\n",
       "       [0.23292479],\n",
       "       [0.97206175],\n",
       "       [0.97704536],\n",
       "       [0.69252664],\n",
       "       [0.66885364],\n",
       "       [0.92831266],\n",
       "       [0.23672733]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model_l.predict(X_test_reshape[:10])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('y_test_cat',y_test_cat.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('y_train_cat',y_train_cat.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35125    even if i'm having a good time i feel bad toda...\n",
       "59835    i need a better reason to live i fantasize abo...\n",
       "24115    the kalimba, or african thumb piano, is a mode...\n",
       "43143    i feel alone but not lonely i know this sounds...\n",
       "52381    i can’t feel empathy for others anymore. somet...\n",
       "                               ...                        \n",
       "49340    i'm home alone, it's been a tough day and i ne...\n",
       "54185    i have been feeling bad lately i feel like i'm...\n",
       "37984    i'm both physically and mentally tired. i go t...\n",
       "8520     i'm wondering how to accept the fact that i di...\n",
       "6759     i just had to call 911 while leaving kroger be...\n",
       "Name: full_text, Length: 48000, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35125            depression\n",
       "59835            depression\n",
       "24115                 happy\n",
       "43143            depression\n",
       "52381            depression\n",
       "                ...        \n",
       "49340            depression\n",
       "54185            depression\n",
       "37984            depression\n",
       "8520     CasualConversation\n",
       "6759     CasualConversation\n",
       "Name: subreddit, Length: 48000, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/X_train.csv')\n",
    "X_test.to_csv('../data/X_test.csv')\n",
    "\n",
    "y_train.to_csv('../data/y_train.csv')\n",
    "y_test.to_csv('../data/y_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
